{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This is a personal project I undertook to detect american sign language in images. I downloaded images from https://public.roboflow.com/object-detection/american-sign-language-letters/1/download/yolov5pytorch for this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that the CUDA is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for generating the pandas DF and resizing images to the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(root, file_type):\n",
    "    return [os.path.join(directory_path, f) for directory_path, directory_name, \n",
    "            files in os.walk(root) for f in files if f.endswith(file_type)]\n",
    "\n",
    "def get_image_sizes(file_list):\n",
    "    heights = []\n",
    "    widths = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        height, width, _ = cv2.imread(file).shape\n",
    "        heights.append(height)\n",
    "        widths.append(width)\n",
    "        \n",
    "    return heights, widths\n",
    "\n",
    "def resize_images(image_list, size, save_dir):\n",
    "    for image in image_list:\n",
    "        img = cv2.imread(image)\n",
    "        img_resized = cv2.resize(img, (size, size))\n",
    "        \n",
    "        new_path = save_dir+image.split(\"/\")[-1]\n",
    "        cv2.imwrite(new_path, img_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./data/ASL/train/labels\"\n",
    "file_path = \"txt\"\n",
    "\n",
    "training_list = []\n",
    "\n",
    "files = list_files(train_dir, file_path)\n",
    "for file in files:\n",
    "    f = open(file, \"r\")\n",
    "    target_class, x_min, y_min, x_max, y_max = f.read().split(\" \")\n",
    "    training_list.append([file, target_class, x_min, y_min, x_max, y_max])\n",
    "    \n",
    "image_dir = \"./data/ASL/train/images/\"\n",
    "file_path = \"jpg\"\n",
    "\n",
    "image_files = list_files(image_dir, file_path)\n",
    "heights, widths = get_image_sizes(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = max(heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image_dir = \"./data/ASL/train/resized_images\"\n",
    "resize_images(image_files, img_size, resized_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image_files = list_files(resized_image_dir, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame(training_list)\n",
    "training_df.columns = [\"path\", \"target_class\",\"x_center\", \"y_center\", \"width\", \"height\"]\n",
    "training_df[\"image_path\"] = image_files\n",
    "training_df[\"resized_image_path\"] = resized_image_files\n",
    "training_df[\"image_width\"] = widths\n",
    "training_df[\"image_height\"] = heights\n",
    "\n",
    "# Update the x_center and y_center relative to their\n",
    "\n",
    "training_df[\"x_min\"] = (training_df[\"x_center\"].astype(float) - training_df[\"width\"].astype(float).multiply(0.5))*training_df[\"image_width\"]\n",
    "training_df[\"x_max\"] = (training_df[\"x_center\"].astype(float) + training_df[\"width\"].astype(float).multiply(0.5))*training_df[\"image_width\"]\n",
    "\n",
    "training_df[\"y_min\"] = (training_df[\"y_center\"].astype(float) - training_df[\"height\"].astype(float).multiply(0.5))*training_df[\"image_height\"]\n",
    "training_df[\"y_max\"] = (training_df[\"y_center\"].astype(float) + training_df[\"height\"].astype(float).multiply(0.5))*training_df[\"image_height\"]\n",
    "\n",
    "bounding_boxes = []\n",
    "\n",
    "for index, row in training_df.iterrows():\n",
    "\n",
    "    bb = np.array([round(float(row[\"x_min\"])), round(float(row[\"y_min\"])), round(float(row[\"x_max\"])), round(float(row[\"y_max\"]))])\n",
    "    bounding_boxes.append(bb)\n",
    "\n",
    "training_df[\"bbs\"] = bounding_boxes\n",
    "# training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have an available GPU to run this notebook in\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_df[[\"resized_image_path\", \"bbs\"]]\n",
    "y = training_df[\"target_class\"]\n",
    "\n",
    "num_classes = len(set(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, bb, img_labels, transform=None, target_transform=None):\n",
    "        self.image_dir = image_dir.values\n",
    "        self.bb = bb.values\n",
    "        self.img_labels = img_labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = read_image(self.image_dir[idx])\n",
    "\n",
    "        label = int(self.img_labels.iloc[idx])\n",
    "        bb = self.bb[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return image, label, bb\n",
    "\n",
    "    \n",
    "batch_size = 16\n",
    "\n",
    "train_ds = ASLDataset(X_train['resized_image_path'], X_train['bbs'], y_train, transform=None)\n",
    "valid_ds = ASLDataset(X_test['resized_image_path'], X_test['bbs'], y_test)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corner_rect(bb, color='red'):\n",
    "    bb = np.array(bb, dtype=np.float32)\n",
    "    return plt.Rectangle((bb[0], bb[1]), bb[2]-bb[0], bb[3]-bb[1], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_corner_bb(im, bb):\n",
    "    plt.imshow(im)\n",
    "    plt.gca().add_patch(create_corner_rect(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 72\n",
    "training_df.iloc[image_index]\n",
    "bbs = training_df.iloc[image_index][\"bbs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll show a sample image to confirm we can read from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = \"red\"\n",
    "img = cv2.imread(training_df.iloc[image_index][\"image_path\"])\n",
    "img = cv2.resize(img, (img_size, img_size))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.gca().add_patch(create_corner_rect(training_df.iloc[image_index][\"bbs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = len(set(y))\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BB, self).__init__()\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        num_ftrs = self.resnet.fc.out_features\n",
    "        \n",
    "        self.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        self.bb = nn.Sequential(nn.BatchNorm1d(num_ftrs), nn.Linear(num_ftrs, 4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        return self.classifier(x), self.bb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epochs(model, optimizer, train_dl, val_dl, epochs=10, C=1000):\n",
    "    idx = 0\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        print(i)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "\n",
    "        for x, y_class, y_bb in train_dl:\n",
    "            \n",
    "            x, y_class, y_bb = x.to(device), y_class.to(device), y_bb.to(device)\n",
    "        \n",
    "            batch = y_class.shape[0]\n",
    "            x = x.float()\n",
    "            y_bb = y_bb.float()\n",
    "            out_class, out_bb = model(x)\n",
    "            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "\n",
    "            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "            loss_bb = loss_bb.sum()\n",
    "            loss = loss_class + loss_bb/C\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            idx += 1\n",
    "            total += batch\n",
    "            sum_loss += loss.item()\n",
    "            \n",
    "        train_loss = sum_loss/total\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl, C)\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(\"i:%4d train_loss:%5.3f val_loss:%5.3f val_acc:%5.3f\" % ((i+1), train_loss, val_loss, val_acc))\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl, C=1000):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0 \n",
    "    for x, y_class, y_bb in valid_dl:\n",
    "        \n",
    "        x, y_class, y_bb = x.to(device), y_class.to(device), y_bb.to(device)\n",
    "\n",
    "        batch = y_class.shape[0]\n",
    "        x = x.float()\n",
    "        y_bb = y_bb.float()\n",
    "        out_class, out_bb = model(x)\n",
    "        \n",
    "        loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
    "        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "        loss_bb = loss_bb.sum()\n",
    "        loss = loss_class + loss_bb/C\n",
    "        _, pred = torch.max(out_class, 1)\n",
    "        correct += pred.eq(y_class).sum().item()\n",
    "        sum_loss += loss.item()\n",
    "        total += batch\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BB()\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_epochs(model, optimizer, train_dl, valid_dl, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to see different predictions\n",
    "predict_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image_sample, x_bb_sample = X_test.iloc[predict_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample = y_test.iloc[predict_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(x_image_sample)\n",
    "\n",
    "xx = torch.cuda.FloatTensor(img[None,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformed = xx.view(1, 3, 416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_class, out_bb = model(x_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_hat = out_bb.detach().cpu().numpy()\n",
    "bb_hat = bb_hat.astype(int)\n",
    "show_corner_bb(img, bb_hat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    assert len(x.shape) == 2\n",
    "    s = np.max(x, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(x - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis]\n",
    "    return e_x / div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_max = softmax(out_class.cpu().detach().numpy())\n",
    "predicted_class = np.array(norm_max).argmax()\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_class = y_test.iloc[[predict_idx]]\n",
    "actual_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
